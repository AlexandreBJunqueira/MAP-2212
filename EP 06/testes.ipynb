{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import gamma\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import minimize\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definindo Variáveis Iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10**6 # Número de vetores thetas\n",
    "k = 10**1 # Número de bins\n",
    "m = 3 # Dimensionalidade\n",
    "x = np.random.randint(0, 11, m) # Vetor x\n",
    "y = np.random.randint(0, 11, m) # Vetor y\n",
    "\n",
    "alfa = x + y # Vetor Alfa = Vetor x + Vetor y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definindo Funções Principais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(theta, alfa, constante):\n",
    "    log_produtorio = np.sum((alfa - 1) * np.log(theta), axis=1) # Para acelerar as operações, faz-se log do produtório (vira somatório)\n",
    "    return np.exp(log_produtorio)/constante\n",
    "\n",
    "def beta_multivariavel(alfa): # Beta(a + b) = Gamma(a)Gamma(b)/Gamma(a + b)\n",
    "    log_produtorio = np.sum(np.log(gamma(alfa)))\n",
    "    return np.exp(log_produtorio)/gamma(np.sum(alfa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gerando Amostras por meio de MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_dir(x, a):\n",
    "    if ((x < 0).any()): return 0.0\n",
    "    t=np.empty_like(x)\n",
    "    for i in range(len(x)):\n",
    "        t[i]=np.power(x[i],(a[i]-1))\n",
    "    return np.prod(t)\n",
    "\n",
    "def cria_cov(alfa):\n",
    "    M = [0.0]*(m - 1)\n",
    "    M = [M]*(m - 1)\n",
    "    M = np.array(M)\n",
    "\n",
    "    for i in range(m - 1):\n",
    "        for j in range(m - 1):\n",
    "\n",
    "            if i == j:\n",
    "                M[i, j] = alfa[i] * (sum(alfa) - alfa[i]) / \\\n",
    "                          ((sum(alfa) ** 2) * (sum(alfa) + 1))  # cálculo das variâncias\n",
    "            else:\n",
    "                M[i, j] = -alfa[i] * alfa[j] / \\\n",
    "                      ((sum(alfa) ** 2) * (sum(alfa) + 1))  # cálculo das covariâncias\n",
    "\n",
    "    return M\n",
    "\n",
    "def met_ac(pontos,p,b,alfa):\n",
    "    for i in range(1,len(pontos)):\n",
    "        ponto_atual = [0]*m\n",
    "        for j in range(m - 1):\n",
    "            ponto_atual[j] = pontos[i-1][j] + p[i,j]\n",
    "        ponto_atual[-1] = 1 - np.sum(ponto_atual[:-1])\n",
    "        ponto_atual = np.array(ponto_atual)\n",
    "        # algoritmo de aceitação de Metropolis\n",
    "        ac = min(1, f_dir(ponto_atual, alfa) /\n",
    "                 f_dir(pontos[i-1], alfa))\n",
    "        if ac >= b[i]:\n",
    "            pontos[i] = np.array(ponto_atual)\n",
    "        else:\n",
    "            pontos[i] = pontos[i-1]\n",
    "\n",
    "    return pontos\n",
    "\n",
    "def calcular_burn_in(cadeia, alfa, limiar_densidade=0.5):\n",
    "    densidades = np.array([f_dir(theta, alfa) for theta in cadeia])\n",
    "    max_densidade = np.max(densidades)\n",
    "    limiar_alto = limiar_densidade * max_densidade\n",
    "\n",
    "    max_index = 0\n",
    "    max_density_value = 0\n",
    "\n",
    "    for i, densidade in enumerate(densidades[:len(cadeia) // 4]):\n",
    "        if densidade >= limiar_alto:\n",
    "            return i\n",
    "        if densidade > max_density_value:\n",
    "            max_density_value = densidade\n",
    "            max_index = i\n",
    "    \n",
    "    return max_index\n",
    "\n",
    "def gera_dir(alfa, n):\n",
    "    \n",
    "    thetas = np.array([np.array([1]*m)/m for _ in range(n)])\n",
    "    M = cria_cov(alfa)\n",
    "    \n",
    "    p = np.random.multivariate_normal([0]*(m - 1), M,size=n)  # gera da Normal Multivariada\n",
    "    b = np.random.uniform(0,1,size=n)\n",
    "    dir=met_ac(thetas,p,b,alfa)\n",
    "\n",
    "    burn_in = calcular_burn_in(dir, alfa)\n",
    "    return dir[burn_in:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a função f_nula\n",
    "def f_nula(theta_1, x_1, x_2, x_3):\n",
    "    theta_3 = (1 - theta_1**(1/2))**2\n",
    "    theta_2 = 1 - theta_1 - theta_3\n",
    "\n",
    "    return (theta_1[0]**x_1) * (theta_2[0]**x_2) * (theta_3[0]**x_3)/beta_multivariavel(alfa)\n",
    "\n",
    "# Função a ser minimizada apenas em theta_1\n",
    "def neg_f_nula(theta_1, x_1, x_2, x_3):\n",
    "    value = -f_nula(theta_1, x_1, x_2, x_3)\n",
    "    return value\n",
    "\n",
    "def calcular_phi(vetor_x):\n",
    "    # Minimizar a função com a restrição\n",
    "    result = minimize(neg_f_nula, x0=0.5, bounds=[(0, 1)], method='Powell', args=(vetor_x[0], vetor_x[1], vetor_x[2]))  # x0 é o palpite inicial para theta_1\n",
    "\n",
    "    # Ponto onde o máximo ocorre e o valor máximo de f_hardy\n",
    "    theta_estrela_1 = result.x[0]\n",
    "    phi = f_nula(np.array([theta_estrela_1]), vetor_x[0], vetor_x[1], vetor_x[2])\n",
    "\n",
    "    # r(theta) = 1\n",
    "    return phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 17, 2],\n",
       " [1, 16, 3],\n",
       " [1, 15, 4],\n",
       " [1, 14, 5],\n",
       " [1, 13, 6],\n",
       " [1, 12, 7],\n",
       " [1, 11, 8],\n",
       " [1, 10, 9],\n",
       " [1, 9, 10],\n",
       " [1, 8, 11],\n",
       " [1, 7, 12],\n",
       " [1, 6, 13],\n",
       " [1, 5, 14],\n",
       " [1, 4, 15],\n",
       " [1, 3, 16],\n",
       " [1, 2, 17],\n",
       " [1, 1, 18],\n",
       " [5, 15, 0],\n",
       " [5, 14, 1],\n",
       " [5, 13, 2],\n",
       " [5, 12, 3],\n",
       " [5, 11, 4],\n",
       " [5, 10, 5],\n",
       " [5, 9, 6],\n",
       " [5, 8, 7],\n",
       " [5, 7, 8],\n",
       " [5, 6, 9],\n",
       " [5, 5, 10],\n",
       " [9, 11, 0],\n",
       " [9, 10, 1],\n",
       " [9, 9, 2],\n",
       " [9, 8, 3],\n",
       " [9, 7, 4],\n",
       " [9, 6, 5],\n",
       " [9, 5, 6],\n",
       " [9, 4, 7]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gerando x_1, x_2, x_3\n",
    "n_hardy = 20\n",
    "lista = []\n",
    "for x_3 in range(2, 19):\n",
    "    lista.append([1, n_hardy - 1 - x_3, x_3])\n",
    "\n",
    "for x_3 in range(0, 11):\n",
    "    lista.append([5, n_hardy - 5 - x_3, x_3])\n",
    "\n",
    "for x_3 in range(0, 8):\n",
    "    lista.append([9, n_hardy - 9 - x_3, x_3])\n",
    "\n",
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_lista_v(lista_f_ord, n, k):\n",
    "    # Define-se os pontos de corte v\n",
    "    # - v_0 = 0; v_k = sup(f(theta))\n",
    "    resto = n % k\n",
    "    tamanho_bin = n // k\n",
    "\n",
    "    # No entanto, quando n%k = c != 0, precisa-se adaptar o tamanho de c bins com um ponto a mais\n",
    "    ajuste = np.concatenate((np.arange(1, resto + 1), np.array([resto] * (k - resto)))) # Array para ajustar o tamanho dos bins\n",
    "    lista_intermed = np.arange(1, k + 1) * tamanho_bin + ajuste\n",
    "    lista_v = np.concatenate(([0], lista_f_ord[lista_intermed - 1]))\n",
    "    return lista_v, lista_intermed\n",
    "\n",
    "def calcular_sev(ev, h=1, t=2):\n",
    "\n",
    "    def Q(d, z):\n",
    "        return stats.chi2.cdf(d, z)\n",
    "\n",
    "    def Q_inv(d, c):\n",
    "        return stats.chi2.ppf(c, d)\n",
    "\n",
    "    def sigma(t, h, c):\n",
    "        return Q(t - h, Q_inv(t, c))\n",
    "\n",
    "    sev_unstandardized = sigma(t, h, ev)\n",
    "    return 1 - sev_unstandardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_7968\\3036942976.py:3: RuntimeWarning: invalid value encountered in sqrt\n",
      "  theta_3 = (1 - theta_1**(1/2))**2\n"
     ]
    }
   ],
   "source": [
    "n = 10**3\n",
    "k = 10\n",
    "\n",
    "e_valores = []\n",
    "for observacoes in lista:\n",
    "    a_priori = np.array([0]*3)\n",
    "    total = np.array(observacoes) + a_priori\n",
    "    correcao = np.array([1]*3)\n",
    "    # Cooreção pois a Dirichlet tem expoente alfa - 1 e a função posteriori de Hardy-Weinber tem expoente alfa\n",
    "\n",
    "    alfa = np.array(total + correcao)\n",
    "    s_estrela = calcular_phi(total)\n",
    "\n",
    "    thetas = gera_dir(alfa, n)\n",
    "    lista_f = f(thetas, alfa, beta_multivariavel(alfa))\n",
    "\n",
    "    lista_f_ord = np.sort(lista_f)\n",
    "    lista_v, lista_intermed = criar_lista_v(lista_f_ord, len(lista_f_ord), k)\n",
    "\n",
    "    fracao = np.concatenate((np.array([0]), lista_intermed))/n\n",
    "        \n",
    "    interp = PchipInterpolator(lista_v, fracao)\n",
    "    ev = interp(s_estrela)\n",
    "    if ev > 1:\n",
    "        ev = 1\n",
    "    sev = calcular_sev(ev)\n",
    "    e_valores.append([observacoes, ev, sev])\n",
    "\n",
    "df1 = pd.DataFrame(e_valores)\n",
    "df1.columns = [\"x\", \"ev\", \"sev\"]\n",
    "\n",
    "e_valores = []\n",
    "for observacoes in lista:\n",
    "    a_priori = np.array([1]*3)\n",
    "    total = np.array(observacoes) + a_priori\n",
    "    correcao = np.array([1]*3)\n",
    "    # Cooreção pois a Dirichlet tem expoente alfa - 1 e a função posteriori de Hardy-Weinber tem expoente alfa\n",
    "\n",
    "    alfa = np.array(total + correcao)\n",
    "    s_estrela = calcular_phi(total)\n",
    "\n",
    "    thetas = gera_dir(alfa, n)\n",
    "    lista_f = f(thetas, alfa, beta_multivariavel(alfa))\n",
    "\n",
    "    lista_f_ord = np.sort(lista_f)\n",
    "    lista_v, lista_intermed = criar_lista_v(lista_f_ord, len(lista_f_ord), k)\n",
    "\n",
    "    fracao = np.concatenate((np.array([0]), lista_intermed))/n\n",
    "        \n",
    "    interp = PchipInterpolator(lista_v, fracao)\n",
    "    ev = interp(s_estrela)\n",
    "    if ev > 1:\n",
    "        ev = 1\n",
    "    sev = calcular_sev(ev)\n",
    "    e_valores.append([observacoes, ev, sev])\n",
    "\n",
    "df2 = pd.DataFrame(e_valores)\n",
    "df2.columns = [\"x\", \"ev\", \"sev\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
